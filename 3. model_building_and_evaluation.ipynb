{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building and Deployment\n",
    "\n",
    "We will use this notebook to build **Logistic Regression** as baseline model. We will further build **Support Vector Classifier-Linear** and **XGBoost** models. Then, we will evaluate the three models based on F1, Precision, Recall and ROC-AUC Scores. The best model will be picked and deployed using AWS-Sagemaker. At last, all the resources will be cleared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if not already installed sagemaker\n",
    "# !pip install sagemaker\n",
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import sklearn libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# import sagemaker libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/clean_data.csv')\n",
    "df = df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bogo</th>\n",
       "      <th>customerid</th>\n",
       "      <th>discount</th>\n",
       "      <th>duration</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>informational</th>\n",
       "      <th>mobile</th>\n",
       "      <th>offerid</th>\n",
       "      <th>...</th>\n",
       "      <th>social</th>\n",
       "      <th>time</th>\n",
       "      <th>totalamount</th>\n",
       "      <th>web</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>78afa995795e4d85b5d9ceeca43f5fef</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9b98b8c7a33c4b65b9aebfe6a799e6d9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ff7cb44e72db4112b270560686f97a23</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4d5c57ea9a6940dd891ad53e9dbe8da0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>97b6993c232946d3b6b9f90530ff8073</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5a8bc65990b245e5a138643cd4eb9837</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>81848348d5584aef9e7374a07ebe6ea1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9b98b8c7a33c4b65b9aebfe6a799e6d9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>28f9666945804ab0bfc63f3ec6ae9af1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>fafdcd668e3743c1bb461111dcafc2a4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bogo                        customerid  discount  duration  email  gender  \\\n",
       "0     1  78afa995795e4d85b5d9ceeca43f5fef         0         7      1       0   \n",
       "1     1  ff7cb44e72db4112b270560686f97a23         0         5      1       0   \n",
       "2     0  97b6993c232946d3b6b9f90530ff8073         0         3      1       1   \n",
       "3     1  81848348d5584aef9e7374a07ebe6ea1         0         7      1       0   \n",
       "4     0  28f9666945804ab0bfc63f3ec6ae9af1         1        10      1       0   \n",
       "\n",
       "     income  informational  mobile                           offerid  ...   \\\n",
       "0  100000.0              0       1  9b98b8c7a33c4b65b9aebfe6a799e6d9  ...    \n",
       "1   39000.0              0       1  4d5c57ea9a6940dd891ad53e9dbe8da0  ...    \n",
       "2   52000.0              1       1  5a8bc65990b245e5a138643cd4eb9837  ...    \n",
       "3  118000.0              0       1  9b98b8c7a33c4b65b9aebfe6a799e6d9  ...    \n",
       "4   44000.0              0       1  fafdcd668e3743c1bb461111dcafc2a4  ...    \n",
       "\n",
       "   social  time  totalamount  web  2013  2014  2015  2016  2017  2018  \n",
       "0       0   0.0        37.67    1     0     0     0     0     1     0  \n",
       "1       1   0.0        48.31    1     0     0     1     0     0     0  \n",
       "2       1   0.0        23.43    0     0     0     0     0     1     0  \n",
       "3       0   0.0        52.24    1     0     0     0     1     0     0  \n",
       "4       1   0.0         5.12    1     0     0     0     0     0     1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['time','customerid','email','informational'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bogo', 'discount', 'duration', 'gender', 'income', 'mobile', 'offerid',\n",
       "       'offersuccessful', 'reward', 'social', 'totalamount', 'web', '2013',\n",
       "       '2014', '2015', '2016', '2017', '2018'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing and Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bogo</th>\n",
       "      <th>discount</th>\n",
       "      <th>duration</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>mobile</th>\n",
       "      <th>offersuccessful</th>\n",
       "      <th>reward</th>\n",
       "      <th>social</th>\n",
       "      <th>totalamount</th>\n",
       "      <th>web</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031366</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bogo  discount  duration  gender    income  mobile  offersuccessful  \\\n",
       "0     1         0  0.571429       0  0.777778       1                1   \n",
       "1     1         0  0.285714       0  0.100000       1                1   \n",
       "2     0         0  0.000000       1  0.244444       1                0   \n",
       "3     1         0  0.571429       0  0.977778       1                0   \n",
       "4     0         1  1.000000       0  0.155556       1                0   \n",
       "\n",
       "   reward  social  totalamount  web  2013  2014  2015  2016  2017  2018  \n",
       "0     0.5       0     0.031366    1     0     0     0     0     1     0  \n",
       "1     1.0       1     0.040225    1     0     0     1     0     0     0  \n",
       "2     0.0       1     0.019509    0     0     0     0     0     1     0  \n",
       "3     0.5       0     0.043497    1     0     0     0     1     0     0  \n",
       "4     0.2       1     0.004263    1     0     0     0     0     0     1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizing the data using min max scaler\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "cols_to_scale = ['income','totalamount','duration','reward']\n",
    "def scaleColumns(df, cols_to_scale):\n",
    "    for col in cols_to_scale:\n",
    "        df[col] = pd.DataFrame(min_max_scaler.fit_transform(pd.DataFrame(df[col])),columns=[col])\n",
    "    return df\n",
    "\n",
    "df = scaleColumns(df, cols_to_scale)\n",
    "df = df.drop(['offerid'], axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "y = df.filter(['offersuccessful'])\n",
    "X = df.drop('offersuccessful', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline using sklearn --> LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# declare the object\n",
    "clf = LogisticRegression(random_state=0)\n",
    "\n",
    "# train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_preds_lr = clf.predict(X_test)\n",
    "\n",
    "data_lr = [['F1', f1_score(y_test, y_preds_lr)], \n",
    "           ['Precision', precision_score(y_test, y_preds_lr)],\n",
    "           ['Recall', recall_score(y_test, y_preds_lr)],\n",
    "           ['ROC-AUC', roc_auc_score(y_test, y_preds_lr)]]  \n",
    "  \n",
    "# Create the pandas DataFrame  \n",
    "results_lr = pd.DataFrame(data_lr, columns = ['Measure', 'Log_Reg'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model1 --> SUPPORT VECTOR CLASSIFIER-LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# declare object\n",
    "clf = SVC(gamma='auto', kernel=\"linear\")\n",
    "\n",
    "# train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_preds_svm = clf.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "data_svm = [['F1', f1_score(y_test, y_preds_svm)], \n",
    "           ['Precision', precision_score(y_test, y_preds_svm)],\n",
    "           ['Recall', recall_score(y_test, y_preds_svm)],\n",
    "           ['ROC-AUC', roc_auc_score(y_test, y_preds_svm)]]  \n",
    "  \n",
    "# Create the pandas DataFrame  \n",
    "results_svm = pd.DataFrame(data_svm, columns = ['Measure', 'SVC'])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model2 -->XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# create the object\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "# train\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_preds_xg = xgb_model.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "data_xg = [['F1', f1_score(y_test, y_preds_xg)], \n",
    "           ['Precision', precision_score(y_test, y_preds_xg)],\n",
    "           ['Recall', recall_score(y_test, y_preds_xg)],\n",
    "           ['ROC-AUC', roc_auc_score(y_test, y_preds_xg)]]  \n",
    "  \n",
    "# Create the pandas DataFrame  \n",
    "results_xg = pd.DataFrame(data_xg, columns = ['Measure', 'XGBoost'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results Comparison and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measure</th>\n",
       "      <th>Log_Reg</th>\n",
       "      <th>SVC</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.841543</td>\n",
       "      <td>0.851419</td>\n",
       "      <td>0.911694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.871918</td>\n",
       "      <td>0.908318</td>\n",
       "      <td>0.896412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.813213</td>\n",
       "      <td>0.801228</td>\n",
       "      <td>0.927507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.852745</td>\n",
       "      <td>0.864150</td>\n",
       "      <td>0.915427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Measure   Log_Reg       SVC   XGBoost\n",
       "0         F1  0.841543  0.851419  0.911694\n",
       "1  Precision  0.871918  0.908318  0.896412\n",
       "2     Recall  0.813213  0.801228  0.927507\n",
       "3    ROC-AUC  0.852745  0.864150  0.915427"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_temp = results_lr.merge(results_svm, left_on='Measure', right_on='Measure')\n",
    "results = results_temp.merge(results_xg, left_on='Measure', right_on='Measure')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clearly both support vector classifier(linear) and xgboost outperforms the baseline.\n",
    "- <font color=\"green\">XGBoost</font> is the best model with 89% precision and 92% recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: starbucks_data/train.csv\n",
      "Path created: starbucks_data/test.csv\n"
     ]
    }
   ],
   "source": [
    "# define data directory\n",
    "data_dir = 'starbucks_data'\n",
    "\n",
    "def make_csv(x, y, filename, data_dir):\n",
    "    '''Merges features and labels and converts them into one csv file with labels in the first column.\n",
    "       :param x: Data features\n",
    "       :param y: Data labels\n",
    "       :param file_name: Name of csv file, ex. 'train.csv'\n",
    "       :param data_dir: The directory where files will be saved\n",
    "       '''\n",
    "    # make data dir, if it does not exist\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    \n",
    "    pd.concat([pd.DataFrame(y), pd.DataFrame(x)], axis=1)\\\n",
    "            .to_csv(os.path.join(data_dir, filename), header=False, index=False)\n",
    "    \n",
    "    \n",
    "    # nothing is returned, but a print statement indicates that the function has run\n",
    "    print('Path created: '+str(data_dir)+'/'+str(filename))\n",
    "\n",
    "# convert the data into proper format\n",
    "make_csv(X_train, y_train, filename='train.csv', data_dir=data_dir)\n",
    "make_csv(X_test, y_test, filename='test.csv', data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sagemaker starts!\n",
    "\n",
    "**This task will be broken down into the following steps:**\n",
    "\n",
    "- Upload the data to S3. \n",
    "- Define xgboost model and a training script.\n",
    "- Train the model and deploy it.\n",
    "- Evaluate the deployed classifier.\n",
    "\n",
    "**NOTE: ** Different models were tried using sklearn and xgboost was picked as the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish session with aws\n",
    "b_session = boto3.session.Session(region_name='eu-central-1')\n",
    "session = sagemaker.Session(boto_session=b_session)\n",
    "role='arn:aws:iam::668154071669:role/service-role/AmazonSageMaker-ExecutionRole-20200120T151312'\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###  Upload the data to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the name of directory created to save the features data\n",
    "data_dir = 'starbucks_data'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'starbucks'\n",
    "\n",
    "# upload all data to S3\n",
    "input_data = session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starbucks/test.csv\n",
      "starbucks/train.csv\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# confirm that data is in S3 bucket\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    print(obj.key)\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# First we make sure that the local directory in which we'd like to store the training and validation csv files exists.\n",
    "data_dir = './data/xgboost'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "    # creating the validation set from the training set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation for the XGBoost algorithm in SageMaker requires that the training and validation datasets should contain no headers or index and that the label should occur first for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_test).to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)\n",
    "pd.concat([y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'validation.csv'), header=False, index=False)\n",
    "pd.concat([y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the data to the s3 bucket\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='0.90-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '0.90-1').\n"
     ]
    }
   ],
   "source": [
    "# We need to retrieve the location of the container which is provided by Amazon for using XGBoost.\n",
    "# As a matter of convenience, the training and inference code both use the same container.\n",
    "container = get_image_uri(session.boto_region_name, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create a SageMaker estimator object for our model.\n",
    "xgb = sagemaker.estimator.Estimator(container, # The location of the container we wish to use\n",
    "                                    role,                                    # What is our current IAM Role\n",
    "                                    train_instance_count=1,                  # How many compute instances\n",
    "                                    train_instance_type='ml.m4.xlarge',      # What kind of compute instances\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "# And then set the algorithm specific parameters.\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simply need to attach the training and validation datasets and then ask SageMaker to set up the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-26 14:02:42 Starting - Starting the training job...\n",
      "2020-02-26 14:02:43 Starting - Launching requested ML instances...\n",
      "2020-02-26 14:03:44 Starting - Preparing the instances for training......\n",
      "2020-02-26 14:04:44 Downloading - Downloading input data...\n",
      "2020-02-26 14:05:22 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-02-26:14:05:22:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-02-26:14:05:22:INFO] File size need to be processed in the node: 3.57mb. Available memory size in the node: 8515.52mb\u001b[0m\n",
      "\u001b[34m[2020-02-26:14:05:22:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:05:22] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:05:22] 29440x16 matrix with 471040 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-02-26:14:05:22:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:05:22] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:05:22] 14501x16 matrix with 232016 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.092086#011validation-error:0.08958\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-error' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-error hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.092188#011validation-error:0.090408\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.089266#011validation-error:0.089511\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.089198#011validation-error:0.088753\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.091202#011validation-error:0.089511\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.087568#011validation-error:0.088339\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.087942#011validation-error:0.088063\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.087602#011validation-error:0.088063\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.087602#011validation-error:0.087994\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.087228#011validation-error:0.087304\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.087194#011validation-error:0.087304\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.087398#011validation-error:0.087649\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.087398#011validation-error:0.087649\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.086481#011validation-error:0.086891\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.085836#011validation-error:0.086753\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.085836#011validation-error:0.086822\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.085802#011validation-error:0.086684\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.085564#011validation-error:0.086684\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.085292#011validation-error:0.086615\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.085394#011validation-error:0.086339\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.084885#011validation-error:0.086477\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.084749#011validation-error:0.085994\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.084783#011validation-error:0.085994\u001b[0m\n",
      "\u001b[34m[14:05:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.084681#011validation-error:0.085856\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.084137#011validation-error:0.085511\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.083899#011validation-error:0.085649\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.084137#011validation-error:0.085373\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.084103#011validation-error:0.08558\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.083899#011validation-error:0.085442\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.083764#011validation-error:0.085029\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.083662#011validation-error:0.084822\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.084103#011validation-error:0.085098\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.08356#011validation-error:0.084684\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.083526#011validation-error:0.084822\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.083254#011validation-error:0.084753\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.082846#011validation-error:0.084615\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.082846#011validation-error:0.084822\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.082541#011validation-error:0.084822\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.082439#011validation-error:0.084339\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.082405#011validation-error:0.084477\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.082371#011validation-error:0.084408\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.082439#011validation-error:0.084477\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.082507#011validation-error:0.08427\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 18 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.082541#011validation-error:0.084063\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.082507#011validation-error:0.084063\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.082235#011validation-error:0.083994\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.082167#011validation-error:0.084339\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.082167#011validation-error:0.084615\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.082235#011validation-error:0.084684\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.082133#011validation-error:0.084684\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.082201#011validation-error:0.084891\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.082167#011validation-error:0.085098\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.082065#011validation-error:0.085235\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.081861#011validation-error:0.085098\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.081929#011validation-error:0.085167\u001b[0m\n",
      "\u001b[34m[14:05:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 30 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.081895#011validation-error:0.085167\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.082235#011validation-error:0.083994\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-02-26 14:05:34 Uploading - Uploading generated training model\n",
      "2020-02-26 14:05:34 Completed - Training job completed\n",
      "Training seconds: 50\n",
      "Billable seconds: 50\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "# We need to tell the endpoint what format the data we are sending is in so that SageMaker can perform the serialization.\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into chunks and send each chunk seperately, accumulating the results.\n",
    "\n",
    "def predict(data, rows=512):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "    \n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "test_X = pd.read_csv(os.path.join(data_dir, 'test.csv'), header=None).values\n",
    "\n",
    "predictions = predict(test_X)\n",
    "predictions = [round(num) for num in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_xg = [['F1', f1_score(y_test, predictions)], \n",
    "           ['Precision', precision_score(y_test, predictions)],\n",
    "           ['Recall', recall_score(y_test, predictions)],\n",
    "           ['ROC-AUC', roc_auc_score(y_test, predictions)]] \n",
    "\n",
    "# Create the pandas DataFrame  \n",
    "aws_results_xg = pd.DataFrame(data_xg, columns = ['Measure', 'XGBoost'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measure</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.911694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.896412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.927507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.915427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Measure   XGBoost\n",
       "0         F1  0.911694\n",
       "1  Precision  0.896412\n",
       "2     Recall  0.927507\n",
       "3    ROC-AUC  0.915427"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aws_results_xg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear the AWS resources- Very Important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': '7273072B96AA6CD3',\n",
       "   'HostId': '7bfzdy+zoMRIB/ys4AGHB4HNWqUq+jyEq9PpipBUnNVXMvMTK4utdh/JRJtnJYM6F6DFwJ+Pxwo=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': '7bfzdy+zoMRIB/ys4AGHB4HNWqUq+jyEq9PpipBUnNVXMvMTK4utdh/JRJtnJYM6F6DFwJ+Pxwo=',\n",
       "    'x-amz-request-id': '7273072B96AA6CD3',\n",
       "    'date': 'Wed, 26 Feb 2020 14:17:59 GMT',\n",
       "    'connection': 'close',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'starbucks/output/xgboost-2020-02-26-14-02-41-707/output/model.tar.gz'},\n",
       "   {'Key': 'starbucks/train.csv'},\n",
       "   {'Key': 'starbucks/validation.csv'},\n",
       "   {'Key': 'starbucks/test.csv'}]}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleting bucket\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measure</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.911694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.896412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.927507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>0.915427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Measure   XGBoost\n",
       "0         F1  0.911694\n",
       "1  Precision  0.896412\n",
       "2     Recall  0.927507\n",
       "3    ROC-AUC  0.915427"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aws_results_xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10268  1113]\n",
      " [  678  9585]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 1113 false positives and 678 false negatives in the data.\n",
    "- ROC-AUC scores tells the degree of separability. It tells us how the model is capable of separating/distinguishing between the two classes. Our model has ROC-AUC score of 91% which indicates a good separability between the classes.\n",
    "- Precision is of 89% and recall is of 92%.\n",
    "- F1 is of 91% which is quite a good figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
